{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de1629c",
   "metadata": {},
   "source": [
    "# Coding Assignment 08: Your task is to cluster reports into 6 clusters using the k-means clustering algorithm with k = 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ecaeccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sharminsultana/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sharminsultana/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Necessary libraries for the task\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "from tqdm.auto import tqdm\n",
    "from nltk.corpus import wordnet\n",
    "import textacy.preprocessing as tprep\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3215828b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug report</th>\n",
       "      <th>Component</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exception thrown during reconcile Got the foll...</td>\n",
       "      <td>APT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GWT Bug Getting the error when trying to insta...</td>\n",
       "      <td>APT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unable to load factory names from container [t...</td>\n",
       "      <td>APT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JdtApt headless build fails for Integrated Ext...</td>\n",
       "      <td>APT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[compiler][apt] Error type detection is too co...</td>\n",
       "      <td>APT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>NPE trying to externalize strings [refactoring...</td>\n",
       "      <td>UI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>Java Search API package has no package.html [s...</td>\n",
       "      <td>UI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>Rename refactoring of inner type does not upda...</td>\n",
       "      <td>UI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>Disable DND operation for logical packages [dn...</td>\n",
       "      <td>UI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>eclipse cant show fully code editor Created at...</td>\n",
       "      <td>UI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2643 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             bug report Component\n",
       "0     Exception thrown during reconcile Got the foll...       APT\n",
       "1     GWT Bug Getting the error when trying to insta...       APT\n",
       "2     Unable to load factory names from container [t...       APT\n",
       "3     JdtApt headless build fails for Integrated Ext...       APT\n",
       "4     [compiler][apt] Error type detection is too co...       APT\n",
       "...                                                 ...       ...\n",
       "2638  NPE trying to externalize strings [refactoring...        UI\n",
       "2639  Java Search API package has no package.html [s...        UI\n",
       "2640  Rename refactoring of inner type does not upda...        UI\n",
       "2641  Disable DND operation for logical packages [dn...        UI\n",
       "2642  eclipse cant show fully code editor Created at...        UI\n",
       "\n",
       "[2643 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read the dataset\n",
    "\"\"\"\n",
    "file = os.getcwd() + '/JDT_Bugs_sm.csv' #location of the dataset\n",
    "df = pd.read_csv(file)\n",
    "df = df[['bug report','Component']].dropna() #Get rid of the irrelavant attributes\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad028e3",
   "metadata": {},
   "source": [
    "# Phase 1: \n",
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0ebbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Clean data\n",
    "\"\"\"\n",
    "# ### Standard cleaning function\n",
    "def clean(text):\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # removing mentions \n",
    "    text = re.sub(\"@\\S+\", \"\", text)\n",
    "    text = re.sub('[-%!@#$]', '', text)\n",
    "    text = re.sub(\"@[A-Za-z0-9]+\",\"\",text)\n",
    "    #Removing numerical data\n",
    "    text = re.sub(r'\\d+','',text)\n",
    "    #Removing currencies \n",
    "    text = re.sub(r'[\\$\\d+\\d+\\$]','',text)\n",
    "    #Handling all date formats\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    #Removing a hyperlink\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '',text)\n",
    "    #Extracting the main domain name of a URL\n",
    "#     text = re.search(r'[\\.\\/]+(.*)\\.',text)\n",
    "#     #Removing all punctuation\n",
    "    text = re.sub(r'[^a-z0-9A-Z_]',' ',text)\n",
    "    return text.strip()\n",
    "\n",
    "df['bug report'] = df['bug report'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd076827",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Normalize data using textacy\n",
    "\"\"\"\n",
    "def normalize(text):\n",
    "        text = tprep.normalize.hyphenated_words(text)\n",
    "        text = tprep.normalize.quotation_marks(text)\n",
    "        text = tprep.normalize.unicode(text)\n",
    "        text = tprep.remove.accents(text)\n",
    "        return text\n",
    "df['bug report'] = df['bug report'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ecb64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0676ced8661248e1a0b5e054ab998887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2643 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use spaCy for lemmatization and also check if token is a legitimate English word \n",
    "\"\"\"\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\",\"ner\"])\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    doc = nlp(str(row[\"bug report\"])) \n",
    "    df.at[i, \"lemma\"] = \" \".join(token.lemma_ for token in doc if wordnet.synsets(str(token)))\n",
    "    ###implement wanted_words by using wordnet from nltk and this check legitimate English word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cba4951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug report</th>\n",
       "      <th>Component</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exception thrown during reconcile Got the foll...</td>\n",
       "      <td>APT</td>\n",
       "      <td>exception thrown reconcile got following excep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GWT Bug Getting the error when trying to insta...</td>\n",
       "      <td>APT</td>\n",
       "      <td>bug getting error trying install installing ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unable to load factory names from container I ...</td>\n",
       "      <td>APT</td>\n",
       "      <td>unable load factory names container i have an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JdtApt headless build fails for Integrated Ext...</td>\n",
       "      <td>APT</td>\n",
       "      <td>headless build fails integrated external tool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Error type detection is too conservative Compi...</td>\n",
       "      <td>APT</td>\n",
       "      <td>error type detection is too conservative compi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>NPE trying to externalize strings I got the fo...</td>\n",
       "      <td>UI</td>\n",
       "      <td>trying externalize strings i got following i t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>Java Search API package has no package html I ...</td>\n",
       "      <td>UI</td>\n",
       "      <td>java search package has no package html i expo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>Rename refactoring of inner type does not upda...</td>\n",
       "      <td>UI</td>\n",
       "      <td>rename inner type does not update constructor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>Disable DND operation for logical packages in ...</td>\n",
       "      <td>UI</td>\n",
       "      <td>disable operation logical packages in i i m no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>eclipse cant show fully code editor Created at...</td>\n",
       "      <td>UI</td>\n",
       "      <td>eclipse ca nt show fully code editor created a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2643 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             bug report Component  \\\n",
       "0     Exception thrown during reconcile Got the foll...       APT   \n",
       "1     GWT Bug Getting the error when trying to insta...       APT   \n",
       "2     Unable to load factory names from container I ...       APT   \n",
       "3     JdtApt headless build fails for Integrated Ext...       APT   \n",
       "4     Error type detection is too conservative Compi...       APT   \n",
       "...                                                 ...       ...   \n",
       "2638  NPE trying to externalize strings I got the fo...        UI   \n",
       "2639  Java Search API package has no package html I ...        UI   \n",
       "2640  Rename refactoring of inner type does not upda...        UI   \n",
       "2641  Disable DND operation for logical packages in ...        UI   \n",
       "2642  eclipse cant show fully code editor Created at...        UI   \n",
       "\n",
       "                                                  lemma  \n",
       "0     exception thrown reconcile got following excep...  \n",
       "1     bug getting error trying install installing ne...  \n",
       "2     unable load factory names container i have an ...  \n",
       "3     headless build fails integrated external tool ...  \n",
       "4     error type detection is too conservative compi...  \n",
       "...                                                 ...  \n",
       "2638  trying externalize strings i got following i t...  \n",
       "2639  java search package has no package html i expo...  \n",
       "2640  rename inner type does not update constructor ...  \n",
       "2641  disable operation logical packages in i i m no...  \n",
       "2642  eclipse ca nt show fully code editor created a...  \n",
       "\n",
       "[2643 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762c14f",
   "metadata": {},
   "source": [
    "# Phase 2: \n",
    "Feature engineering (text vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a220563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Represent each report as a vector of tf-idf values.\n",
    "\"\"\"\n",
    "tfidf = TfidfVectorizer(stop_words=stopwords, use_idf=True)\n",
    "\n",
    "###TFIDF for lemmas\n",
    "tfidf_lemmas = tfidf.fit_transform(df[\"lemma\"])\n",
    "\n",
    "X = tfidf_lemmas.toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395d697",
   "metadata": {},
   "source": [
    "# Phase 3:\n",
    "K-means implimentation: Implement k-means using cosine similarity on vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5db1f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_centroids(data, k, seed=None):\n",
    "    '''Randomly choose k data points as initial centroids'''\n",
    "    if seed is not None: # useful for obtaining consistent results\n",
    "        np.random.seed(20)\n",
    "    n = data.shape[0] # number of data points\n",
    "        \n",
    "    # Pick K indices from range [0, N).\n",
    "    rand_indices = np.random.randint(0, n, k)\n",
    "    centroids = data[rand_indices,:]\n",
    "    \n",
    "    return centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01371526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assign clusters based on cosine distance\n",
    "\"\"\"\n",
    "def assign_clusters(data, centroids):\n",
    "    \n",
    "    # Compute cosine distances between each data point and the set of centroids:\n",
    "    distances_from_centroids = pairwise_distances(data, centroids, metric='cosine')\n",
    "    \n",
    "    # Compute number of cluster assignments for each data point:\n",
    "    cluster_assignment = np.argmin(distances_from_centroids, axis = 1)\n",
    "    \n",
    "    return cluster_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feee58f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assign new centers for each epoch\n",
    "\"\"\"\n",
    "def revise_centroids(data, k, cluster_assignment):\n",
    "    new_centroids = []\n",
    "    for i in range(k):\n",
    "        # Select all data points that belong to cluster i.\n",
    "        member_data_points = data[cluster_assignment == i]\n",
    "        # Compute the mean of the data points. \n",
    "        centroid = member_data_points.mean(axis = 0)\n",
    "        centroid = centroid\n",
    "        new_centroids.append(centroid)\n",
    "    new_centroids = np.array(new_centroids)\n",
    "    \n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8430dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function runs k-means on given data and initial set of centroids.\n",
    "   maxiter: maximum number of iterations to run.\n",
    "'''\n",
    "def kmeans(data, k, initial_centroids, maxiter):\n",
    "    centroids = initial_centroids[:]\n",
    "    prev_cluster_assignment = None\n",
    "\n",
    "    for itr in range(maxiter):        \n",
    "\n",
    "        # 1. Make cluster assignments using nearest centroids\n",
    "        cluster_assignment = assign_clusters(data, centroids)\n",
    "            \n",
    "        # 2. Compute a new centroid for each of the k clusters, averaging all data points assigned to that cluster.\n",
    "        centroids = revise_centroids(data, k, cluster_assignment)\n",
    "            \n",
    "        # Check for convergence: if none of the assignments changed, stop\n",
    "        if prev_cluster_assignment is not None and (prev_cluster_assignment==cluster_assignment).all():\n",
    "            break\n",
    "        \n",
    "        # Print number of new assignments \n",
    "        if prev_cluster_assignment is not None:\n",
    "            num_changed = sum(abs(prev_cluster_assignment-cluster_assignment))\n",
    "\n",
    "        prev_cluster_assignment = cluster_assignment[:]\n",
    "        \n",
    "    return centroids, cluster_assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae270223",
   "metadata": {},
   "source": [
    "# Phase 4.1: \n",
    "Run k-means on the tf-idf vectors of reports for 10 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5da8d274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Cluster Assignments:  [397 417 452 440 735 202]\n",
      "Epoch:  1\n",
      "Cluster Assignments:  [257 601 704 426 461 194]\n",
      "Epoch:  2\n",
      "Cluster Assignments:  [336 439 478 422 431 537]\n",
      "Epoch:  3\n",
      "Cluster Assignments:  [444 515 267 426 353 638]\n",
      "Epoch:  4\n",
      "Cluster Assignments:  [422 357 462 556 503 343]\n",
      "Epoch:  5\n",
      "Cluster Assignments:  [410 347 427 683 617 159]\n",
      "Epoch:  6\n",
      "Cluster Assignments:  [500 543 254 428 447 471]\n",
      "Epoch:  7\n",
      "Cluster Assignments:  [223 451 418 349 666 536]\n",
      "Epoch:  8\n",
      "Cluster Assignments:  [471 452 267 428 408 617]\n",
      "Epoch:  9\n",
      "Cluster Assignments:  [487 394 237 355 640 530]\n"
     ]
    }
   ],
   "source": [
    "k = 6 ##Randomly choose 6 data points from 6 different target\n",
    "\n",
    "for e in range (0,10): ###10 epochs \n",
    "    print (\"Epoch: \",e)\n",
    "    initial_centroids = get_initial_centroids(X, k)\n",
    "    \n",
    "    centroids, cluster_assignment = kmeans(X, k, initial_centroids, maxiter=1000)\n",
    "\n",
    "    print(\"Cluster Assignments: \",np.bincount(cluster_assignment))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e46c95",
   "metadata": {},
   "source": [
    "# Phase 4.2: \n",
    "Is the resulted clustering reasonably consistent with the  component labels? Justify your finding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03680f08",
   "metadata": {},
   "source": [
    "In the resultant clusters, index[0] represents # of clusters in APT, index[1] represents clusters in Core, index [2] is for Debug, index [3] presents num of clusters in Doc. Similarly index [4] and [5] represents the number of clusters in Text and UI. In the original given dataset, there are 404 bug reports for APT, 654 in Core, 120 in Debug, 188 in Doc, 404 in Text and 873 reports in UI. It is observed from the results that number of cluster assigments is not that much satisfactory. So we can say that Cosine similarity alone is not a sufficiently good comparison function for good text clustering. And K-means clustering is not guaranteed to give the same answer every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1393a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
